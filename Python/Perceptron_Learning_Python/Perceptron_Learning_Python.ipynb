{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Perceptron Algorithm\n",
    "\n",
    "In this Jupyter notebook, we will implement the perceptron algorithm written with Python utilizing the [iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n",
    "\n",
    "Contrary to the [Julia](https://github.com/jzhu95/DATA_4319/blob/master/Julia/Perceptron_Learning_Julia/Perceptron.ipynb) perceptron algorithm where we wrote every function and tested the data ourselves, we will utilize the package of scikit-learn, or sklearn.\n",
    "\n",
    "We will also implement the following packages: \n",
    "* scikit-learn [documentation](https://github.com/scikit-learn/scikit-learn)\n",
    "* numpy [documentation](https://github.com/numpy/numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perceptron algorithm is utilized for the supervised learning of binary classifiers (meaning its task is to classify the elements of a set into two groups on the basis of the classification rule). It is also a single-layer neural network consisting of four main parts: input values, weights and bias, net sum, and an activation function.\n",
    "\n",
    "![Perceptron](perceptronTheory.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Create our X and y data\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first five observations of our y data\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first five observations of our x data.\n",
    "# Notice that there are four independent variables (features)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split The Iris Data Into Training And Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 70% training data and 30% test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess The X Data By Scaling\n",
    "\n",
    "Data preprocessing is an extremely important step in machine learning or deep learning. We cannot just dump the raw data into a model and expect it to perform well. Even if we build a complex, well structured model, its performance gets as good as the data we feed to it. If we use them without any scaling, machine learning models might give more importance to the features with higher values. Models tend to perform better and converge faster when the features are on a relatively similar scale. Thus, we need to process the raw data to boost the performance of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the scaler, which standarizes all the features to have mean=0 and unit variance\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the scaler to the X training data\n",
    "X_train_std = sc.transform(X_train)\n",
    "\n",
    "# Apply the SAME scaler to the X test data\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train A Perceptron Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=0.1,\n",
       "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a perceptron object with the parameters: learning rate of 0.1, tolerance of 0.001\n",
    "ppn = Perceptron(tol = .001, eta0=0.1, random_state=0)\n",
    "\n",
    "# Train the perceptron\n",
    "ppn.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply The Trained Learner To Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the trained perceptron on the X data to make predicts for the y test data\n",
    "y_pred = ppn.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 1, 2, 2,\n",
       "       2, 1, 0, 0, 1, 2, 2, 1, 0, 1, 2, 1, 2, 0, 2, 2, 0, 0, 0, 0, 2, 2,\n",
       "       0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the predicted y test data\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare The Predicted Y With The True Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 2, 2, 2, 0, 0, 2, 1, 2, 0, 2, 0, 0, 1, 2, 1, 1, 2, 2,\n",
       "       1, 1, 0, 0, 1, 2, 2, 0, 0, 1, 2, 1, 2, 0, 1, 1, 0, 0, 0, 0, 2, 2,\n",
       "       0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the true y test data\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Accuracy Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "# View the accuracy of the model, which is: 1 - (observations predicted wrong / total observations)\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
